---
title: You Only Look Once: Unified, Real-Time Object Detection
date: 2022-11-23
tags: Object Detection
categories: Object Detection
cover: /images/文章图片/20220926-初等变换和初等矩阵/001.jpg
excerpt: 我们使用单个神经网络，在一次评估中直接从完整图像上预测边界框和类别概率。由于整个检测流程仅用一个网络，所以可以直接对检测性能进行端到端的优化。
---
## 摘要

我们提出的YOLO是一种新的目标检测方法。以前的目标检测方法通过重新利用分类器来执行检测。与先前的方案不同，我们将目标检测看作回归问题从空间上定位边界框（bounding box）并预测该框的类别概率。我们使用单个神经网络，在一次评估中直接从完整图像上预测边界框和类别概率。由于整个检测流程仅用一个网络，所以可以直接对检测性能进行端到端的优化。

我们架构运行是非常快的，YOLO模型的基本版本以45帧/秒的速度实时处理图像。模型的一个较小版本——快速YOLO，以155帧／秒这样惊人的速度运行，却能实现相当于其它实时检测器两倍的mAP。与最先进的检测系统相比，YOLO虽然产生了较多的定位误差，但它几乎不会发生把背景预测为目标这样的假阳性（False Positive）的错误。最后，YOLO能学习到泛化性很强的目标表征。当从自然图像学到的模型用于其它领域如艺术画作时，它的表现都优于包括DPM和R-CNN在内的其它检测方法。

## 1. 引言

人们只需瞄一眼图像，立即知道图像中的物体是什么，它们在哪里以及它们如何相互作用。人类的视觉系统是快速和准确的，使得我们在无意中就能够执行复杂的任务，如驾驶。快速且准确的目标检测算法可以让计算机在没有专门传感器的情况下驾驶汽车，使辅助设备能够向人类用户传达实时的场景信息，并解锁通用响应机器人系统的潜能。


目前的检测系统通过重用分类器来执行检测。为了检测目标，这些系统为该目标提供一个分类器，在测试图像的不同的位置和不同的尺度上对其进行评估。像deformable parts models（DPM）这样的系统使用滑动窗口方法，其分类器在整个图像上均匀间隔的位置上运行[10]。


最近的方法，如R-CNN使用region proposal策略，首先在图像中生成潜在的边界框（bounding box），然后在这些框上运行分类器。在分类之后，执行用于细化边界框的后处理，消除重复的检测，并根据场景中的其它目标为边界框重新打分[13]。这些复杂的流程是很慢，很难优化的，因为每个独立的部分都必须单独进行训练。

我们将目标检测看作是一个单一的回归问题，直接从图像像素得到边界框坐标和类别概率。使用我们的系统——You Only Look Once（YOLO），便能得到图像上的物体是什么和物体的具体位置。


YOLO非常简单（见图1），它仅用单个卷积网络就能同时预测多个边界框和它们的类别概率。YOLO在整个图像上训练，并能直接优化检测性能。与传统的目标检测方法相比，这种统一的模型下面所列的一些优点。

第一，YOLO速度非常快。由于我们将检测视为回归问题，所以我们不需要复杂的流程。测试时，我们在一张新图像上简单的运行我们的神经网络来预测检测结果。在Titan X GPU上不做批处理的情况下，YOLO的基础版本以每秒45帧的速度运行，而快速版本运行速度超过150fps。这意味着我们可以在不到25毫秒的延迟内实时处理流媒体视频。此外，YOLO实现了其它实时系统两倍以上的平均精度。关于我们的系统在网络摄像头上实时运行的演示，请参阅我们的项目网页：http://pjreddie.com/yolo/。


第二，YOLO是在整个图像上进行推断的。与基于滑动窗口和候选框的技术不同，YOLO在训练期间和测试时都会顾及到整个图像，所以它隐式地包含了关于类的上下文信息以及它们的外观。Fast R-CNN是一种很好的检测方法[14]，但由于它看不到更大的上下文，会将背景块误检为目标。与Fast R-CNN相比，YOLO的背景误检数量少了一半。


第三，YOLO能学习到目标的泛化表征。把在自然图像上进行训练的模型，用在艺术图像进行测试时，YOLO大幅优于DPM和R-CNN等顶级的检测方法。由于YOLO具有高度泛化能力，因此在应用于新领域或碰到意外的输入时不太可能出故障。


YOLO在精度上仍然落后于目前最先进的检测系统。虽然它可以快速识别图像中的目标，但它在定位某些物体尤其是小的物体上精度不高。我们在实验中会进一步探讨精度／时间的权衡。我们所有的训练和测试代码都是开源的，而且各种预训练模型也都可以下载。






